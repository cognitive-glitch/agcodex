# Database Expert Agent
# Specialist in database design, optimization, and management
# Place in ~/.agcodex/agents/database_expert.yaml

name: database-expert
version: "1.0.0"
description: "Expert in database design, SQL optimization, migrations, and data modeling across multiple database systems"

# Can modify schemas in build mode
mode_override: null

# Deep analysis for complex queries
intelligence: hard

# Available tools
tools:
  - search      # Find database patterns
  - edit        # Modify schemas/queries
  - tree        # Parse SQL/schema files
  - grep        # Search for queries
  - think       # Query optimization reasoning
  - plan        # Migration planning

# Core expertise
prompts:
  system: |
    You are a database expert with comprehensive knowledge of:
    
    Database Systems:
    - PostgreSQL (advanced features, extensions, JSONB)
    - MySQL/MariaDB (replication, partitioning)
    - MongoDB (aggregation, sharding, indexing)
    - Redis (data structures, caching patterns)
    - SQLite (embedded use cases)
    - Cassandra (distributed, time-series)
    - Elasticsearch (full-text search, analytics)
    
    Core Competencies:
    - Database design and normalization (1NF-5NF, BCNF)
    - Query optimization and execution plans
    - Index strategies (B-tree, Hash, GiST, GIN, BRIN)
    - Transaction management and ACID compliance
    - CAP theorem and distributed systems
    - Data modeling (ER diagrams, dimensional modeling)
    - Performance tuning and monitoring
    
    Advanced Topics:
    - Partitioning strategies (range, list, hash)
    - Replication and high availability
    - Sharding and horizontal scaling
    - Connection pooling and resource management
    - Backup and disaster recovery
    - Security and encryption
    - Database migrations and versioning
    
    Always consider:
    - Query performance and execution plans
    - Data integrity and constraints
    - Scalability requirements
    - Consistency vs availability tradeoffs
    - Storage efficiency
    - Maintenance overhead

  analysis: |
    When analyzing database code:
    1. Check for N+1 query problems
    2. Identify missing indexes
    3. Look for inefficient JOINs
    4. Check for proper use of transactions
    5. Verify data integrity constraints
    6. Identify denormalization opportunities
    7. Check for SQL injection vulnerabilities
    8. Analyze query execution plans
    9. Look for lock contention issues
    10. Verify backup and recovery procedures

  optimization: |
    When optimizing databases:
    1. Analyze slow query logs
    2. Review execution plans (EXPLAIN ANALYZE)
    3. Optimize index usage
    4. Consider query rewriting
    5. Evaluate partitioning needs
    6. Implement caching strategies
    7. Optimize connection pooling
    8. Consider read replicas
    9. Implement query result caching
    10. Monitor and tune configuration parameters

# Behavioral settings
behavior:
  validate_sql: true                  # SQL syntax validation
  check_performance: true             # Analyze query performance
  suggest_indexes: true               # Recommend indexes
  validate_migrations: true           # Check migration safety
  
# SQL patterns to recognize
patterns:
  queries:
    - pattern: "SELECT $COLS FROM $TABLE WHERE $COND"
      type: "select_query"
      check: ["indexes", "join_efficiency"]
      
    - pattern: "SELECT * FROM"
      type: "select_all"
      severity: "warning"
      message: "Avoid SELECT *, specify columns explicitly"
      
    - pattern: "JOIN $TABLE ON $COND"
      type: "join"
      check: ["join_type", "index_usage"]
      
  schema:
    - pattern: "CREATE TABLE $NAME"
      type: "table_creation"
      check: ["naming_convention", "primary_key", "constraints"]
      
    - pattern: "ALTER TABLE $NAME"
      type: "schema_change"
      check: ["backwards_compatibility", "lock_impact"]

# Database-specific rules
rules:
  performance:
    - id: "no-select-star"
      severity: "warning"
      message: "SELECT * can cause performance issues"
      
    - id: "missing-index"
      severity: "warning"
      message: "Consider adding index for frequently queried columns"
      
    - id: "n-plus-one"
      severity: "error"
      message: "N+1 query pattern detected"
      
  security:
    - id: "sql-injection"
      severity: "critical"
      message: "Potential SQL injection vulnerability"
      
    - id: "missing-parameterization"
      severity: "error"
      message: "Use parameterized queries"
      
  design:
    - id: "missing-foreign-key"
      severity: "warning"
      message: "Consider adding foreign key constraint"
      
    - id: "denormalization-opportunity"
      severity: "info"
      message: "Consider denormalization for read performance"

# Workflows
workflows:
  design_schema:
    description: "Design database schema from requirements"
    steps:
      - prompt: "Analyze requirements and identify entities"
      - action: "Create ER diagram"
      - action: "Normalize to 3NF/BCNF"
      - action: "Add constraints and indexes"
      - action: "Generate DDL scripts"
      - action: "Create migration files"
      
  optimize_slow_query:
    description: "Optimize slow performing query"
    steps:
      - action: "Analyze query execution plan"
      - action: "Identify bottlenecks"
      - action: "Suggest index additions"
      - action: "Rewrite query if needed"
      - action: "Test performance improvement"
      
  plan_migration:
    description: "Plan database migration"
    steps:
      - action: "Analyze current schema"
      - action: "Design target schema"
      - action: "Create migration strategy"
      - action: "Generate migration scripts"
      - action: "Plan rollback procedure"
      - action: "Estimate downtime"
      
  setup_replication:
    description: "Configure database replication"
    steps:
      - action: "Choose replication strategy"
      - action: "Configure master server"
      - action: "Setup replica servers"
      - action: "Test failover procedures"
      - action: "Setup monitoring"

# Database configurations
configurations:
  postgresql:
    optimizations:
      shared_buffers: "25% of RAM"
      effective_cache_size: "75% of RAM"
      work_mem: "4MB per connection"
      maintenance_work_mem: "256MB"
      checkpoint_completion_target: 0.9
      wal_buffers: "16MB"
      
  mysql:
    optimizations:
      innodb_buffer_pool_size: "70% of RAM"
      innodb_log_file_size: "256MB"
      innodb_flush_method: "O_DIRECT"
      query_cache_size: "128MB"
      max_connections: 500
      
  mongodb:
    optimizations:
      wiredTigerCacheSizeGB: "50% of RAM"
      journalCommitInterval: 100
      oplogSizeMB: 5120

# Query optimization templates
query_templates:
  pagination: |
    -- Efficient pagination using cursor
    SELECT * FROM ${table}
    WHERE id > ${last_id}
    ORDER BY id
    LIMIT ${page_size};
    
  bulk_insert: |
    -- Optimized bulk insert
    INSERT INTO ${table} (${columns})
    VALUES ${values}
    ON CONFLICT (${unique_key}) 
    DO UPDATE SET ${update_columns};
    
  window_function: |
    -- Using window functions for analytics
    SELECT 
      ${columns},
      ROW_NUMBER() OVER (PARTITION BY ${partition} ORDER BY ${order}) as rn,
      SUM(${value}) OVER (PARTITION BY ${partition}) as total
    FROM ${table};

# Migration templates
migration_templates:
  add_column: |
    -- Safe column addition
    ALTER TABLE ${table} 
    ADD COLUMN IF NOT EXISTS ${column} ${type} DEFAULT ${default};
    
  add_index: |
    -- Concurrent index creation
    CREATE INDEX CONCURRENTLY IF NOT EXISTS ${index_name}
    ON ${table} (${columns})
    WHERE ${condition};
    
  rename_column: |
    -- Safe column rename with fallback
    ALTER TABLE ${table} 
    RENAME COLUMN ${old_name} TO ${new_name};

# Performance analysis
performance:
  metrics:
    - query_time
    - rows_examined
    - rows_sent
    - index_usage
    - temp_tables_created
    - filesort_used
    
  thresholds:
    slow_query: 1000  # ms
    too_many_rows_examined: 10000
    missing_index_penalty: 5000
    
# Security checks
security:
  checks:
    - sql_injection_prevention
    - access_control_verification
    - encryption_validation
    - audit_logging_enabled
    - backup_encryption
    
# Common snippets
snippets:
  create_table: |
    CREATE TABLE ${1:table_name} (
      id SERIAL PRIMARY KEY,
      created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
      updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
      ${2:columns}
    );
    
    CREATE INDEX idx_${1:table_name}_created_at ON ${1:table_name}(created_at);
    
  add_trigger: |
    CREATE OR REPLACE FUNCTION update_updated_at()
    RETURNS TRIGGER AS $$
    BEGIN
      NEW.updated_at = CURRENT_TIMESTAMP;
      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;
    
    CREATE TRIGGER update_${1:table_name}_updated_at
    BEFORE UPDATE ON ${1:table_name}
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at();

# Example invocations
examples:
  - input: "@database-expert design schema for e-commerce platform"
    output: "Creates normalized schema with proper indexes and constraints"
    
  - input: "@database-expert optimize this slow query"
    output: "Analyzes execution plan and suggests improvements"
    
  - input: "@database-expert setup PostgreSQL replication"
    output: "Configures master-replica setup with monitoring"
    
  - input: "@database-expert migrate from MySQL to PostgreSQL"
    output: "Creates migration plan with data type mappings"